{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 30px 60px; border: 5px skyblue solid; border-radius: 30px; max-width: 600px; font-size: 2rem; line-height: 3rem; color: black; font-family: sans-serif;\">\n",
    "\n",
    "  <div style=\"font-size: 1.5rem; font-weight: 200;\">[CM3070] Final Project - BSc CS University of London</div>\n",
    "  <div style=\"font-size: 1.5rem; font-weight: 500;\">Deep Learning on Satellite Imagery</div>\n",
    "  <div style=\"font-size: 2rem; color: dodgerblue; font-weight: bold;\">by Arjun Bajaj</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to TensorFlow Lite for Deployment on the Pico\n",
    "\n",
    "This notebook focuses on converting the best (final) model created in the previous notebook, into the TensorFlow Lite format to deploy it on the Raspberry Pi Pico Microcontroller.\n",
    "\n",
    "To convert a Keras model into the `TFLite` format, the model has to be loaded, the converter has to be initialized, and optimizations configured. The converter also needs a function which provides it with sample data so that the model is configured appropriately for production. This _Representative Dataset Generator_ ensures that the Tensor Arenas are of the correct types and sizes.\n",
    "\n",
    "The `TFLite` model is written to disk, but it cannot be used directly on the Pico, as most microcontrollers (including the Pico) do not have a filesystem to load files from. Hence, the `TFLite` binary is converted into a `C Header` file which allows the model to be embedded into the `C++` code directly.\n",
    "\n",
    "When converting the model from `Keras` to `TFLite` some optimizations are applied such as quantization, which reduce the model size considerably. However, these optimizations come at a slight cost of accuracy. To ensure the model is performing well, the accuracy can be tested in Python. This is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import subprocess\n",
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from core import load_eurosat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21600 files belonging to 10 classes.\n",
      "Found 2700 files belonging to 10 classes.\n",
      "Found 2700 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the validation and test datasets.\n",
    "# The validation dataset is used to check the accuracy difference\n",
    "# between the Keras and TFLite models. The test dataset is only used\n",
    "# for the Representative Dataset Generator at this stage.\n",
    "(_, val, test) = load_eurosat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/2z/5ll18j2j6xx6m8q0zjbjpj480000gn/T/tmp0e75jegl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/2z/5ll18j2j6xx6m8q0zjbjpj480000gn/T/tmp0e75jegl/assets\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Converted\n"
     ]
    }
   ],
   "source": [
    "# Load the final model (trained in the previous notebook)\n",
    "model = tf.keras.models.load_model(\"../artifacts/eurosat.keras\")\n",
    "\n",
    "# Intialize the TFLite converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Apply Default Optimizations\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Create the Representative Dataset Generator\n",
    "def representative_dataset_generator():\n",
    "  # Take the first batch of images\n",
    "  images, _labels = test.take(1).as_numpy_iterator().next()\n",
    "\n",
    "  # Convert the images to float32 with a surrounding dimension\n",
    "  for image in images:\n",
    "    yield [np.array(image, dtype=np.float32, ndmin=4)]\n",
    "\n",
    "# Set the generator function on the converter's object\n",
    "converter.representative_dataset = representative_dataset_generator\n",
    "\n",
    "# Invoke the converter to generate the TFLite model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Write the TFLite model to disk\n",
    "open(\"../artifacts/eurosat.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "# Convert the TFLite file to a C Header file.\n",
    "# This requires the `xxd` command, usually available on Linux and macOS.\n",
    "subprocess.run([\"xxd\", \"-i\", \"eurosat.tflite\", \"eurosat.h\"], cwd=\"../artifacts\")\n",
    "\n",
    "# Move the C Header file to the Pico's source directory\n",
    "shutil.move(\"../artifacts/eurosat.h\", \"../lite/pico/eurosat.h\")\n",
    "\n",
    "print('Model Converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite Model Size: 36.41 kb\n",
      "Header File Size: 224.63 kb\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the TFLite file and the converted Header File\n",
    "tflite_size = pathlib.Path('../artifacts/eurosat.tflite').stat().st_size / 1024\n",
    "header_size = pathlib.Path('../lite/pico/eurosat.h').stat().st_size / 1024\n",
    "print(f\"TFLite Model Size: {tflite_size:.2f} kb\")\n",
    "print(f\"Header File Size: {header_size:.2f} kb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Accuracy of TFLite Model\n",
    "\n",
    "In this step, the validation accuracy of the TFLite model is evaluated, as converting the model leads to a slight drop in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 90.96%\n"
     ]
    }
   ],
   "source": [
    "# Load the TFLite Model\n",
    "lite = tf.lite.Interpreter('../artifacts/eurosat.tflite')\n",
    "\n",
    "# Allocate Tensors\n",
    "lite.allocate_tensors()\n",
    "\n",
    "# Variables to store the total and correct predictions\n",
    "true = []\n",
    "pred = []\n",
    "\n",
    "# Iterate over the validation dataset\n",
    "for image, label in val.unbatch():\n",
    "  # Write the image to the input tensor\n",
    "  lite.set_tensor(lite.get_input_details()[0]['index'], [image])\n",
    "\n",
    "  # Invoke the TFLite model inference\n",
    "  lite.invoke()\n",
    "\n",
    "  # Read the result from the output tensor\n",
    "  output = lite.get_tensor(lite.get_output_details()[0]['index'])\n",
    "  \n",
    "  # Get the predicted label using the argmax function\n",
    "  result = np.argmax(output)\n",
    "\n",
    "  # Append the true and predicted labels to the lists\n",
    "  true.append(label)\n",
    "  pred.append(result)\n",
    "\n",
    "\n",
    "val_accuracy = metrics.accuracy_score(true, pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "The final model's highest validation accuracy was `91.33%`. After converting the `Keras` model to `TFLite`, the validation accuracy is `90.96%`, leading to a drop of `0.37` percentage points.\n",
    "\n",
    "In the next notebook, the final model is evaluated on the test dataset, and the inference results from the Pico are explored and visualized.\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
